{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "462ff523"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "from yellowbrick.model_selection import learning_curve\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.utils import shuffle as shf\n",
        "import pickle\n",
        "import os\n",
        "import glob as gb"
      ],
      "id": "462ff523"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef0fd5af"
      },
      "source": [
        "# Loading and saving images as .npy files so we could deal with them"
      ],
      "id": "ef0fd5af"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b31f208e"
      },
      "outputs": [],
      "source": [
        "code = {'basal cell carcinoma':0, 'melanoma':1, 'pigmented benign keratosis':2}\n",
        "#function to return the class of the images from its number.\n",
        "def getcode(n) :\n",
        "    for x , y in code.items() :\n",
        "        if n == y :\n",
        "            return x"
      ],
      "id": "b31f208e"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6vVqGPzs67fg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8409672-ff60-4aa5-bb01-33869964dae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',  force_remount=True)"
      ],
      "id": "6vVqGPzs67fg"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "838ba887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "cfc9a842-fe54-4d57-c3b3-1686313e62d0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-076168aa4345>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtrainpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/Skin cancer ISIC The International Skin Imaging Collaboration/Untitled folder/Train/'"
          ]
        }
      ],
      "source": [
        "#the directory that contain the train images set\n",
        "trainpath='/content/drive/MyDrive/Colab Notebooks/Cancer-3-class/Train/'\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "for folder in  os.listdir(trainpath) :\n",
        "    files = gb.glob(pathname= str( trainpath + folder + '/*.jpg'))\n",
        "    for file in files:\n",
        "        image = cv2.imread(file)\n",
        "        #resize images to 64 x 64 pixels\n",
        "        image_array = cv2.resize(image , (64,64))\n",
        "        X_train.append(list(image_array))\n",
        "        y_train.append(code[folder])\n",
        "np.save('X_train',X_train)\n",
        "np.save('y_train',y_train)\n",
        "\n"
      ],
      "id": "838ba887"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bsoVBOisB809"
      },
      "id": "bsoVBOisB809",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2369855"
      },
      "outputs": [],
      "source": [
        "#the directory that contain the test images set\n",
        "testpath='/content/drive/MyDrive/Colab Notebooks/Cancer-3-class/Test/'\n",
        "X_test = []\n",
        "y_test = []\n",
        "for folder in  os.listdir(testpath) :\n",
        "    files = gb.glob(pathname= str( testpath + folder + '/*.jpg'))\n",
        "    for file in files:\n",
        "        image = cv2.imread(file)\n",
        "        #resize images to 64 x 64 pixels\n",
        "        image_array = cv2.resize(image , (64,64))\n",
        "        X_test.append(list(image_array))\n",
        "        y_test.append(code[folder])\n",
        "np.save('X_test',X_test)\n",
        "np.save('y_test',y_test)"
      ],
      "id": "d2369855"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b4ca4bb"
      },
      "source": [
        "The .npy files are then uploaded to Google Drive"
      ],
      "id": "8b4ca4bb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30c3ef52"
      },
      "source": [
        "# Loading the .npy files as numpy arrays"
      ],
      "id": "30c3ef52"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b226f4d1"
      },
      "outputs": [],
      "source": [
        "#X_train, X_test contain the images as numpy arrays, while y_train, y_test contain the class of each image\n",
        "loaded_X_train = np.load('./X_train.npy')\n",
        "loaded_X_test = np.load('./X_test.npy')\n",
        "loaded_y_train = np.load('./y_train.npy')\n",
        "loaded_y_test = np.load('./y_test.npy')"
      ],
      "id": "b226f4d1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37215c2a"
      },
      "outputs": [],
      "source": [
        "print(loaded_X_train.shape)\n",
        "#the shape return dimensions of X_train, we have 1276 images of 64 x 64 pixels.\n",
        "#while the forth dimension stores the RGB information of each pixel"
      ],
      "id": "37215c2a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7836d805"
      },
      "outputs": [],
      "source": [
        "print(loaded_X_test.shape)"
      ],
      "id": "7836d805"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2d0923f"
      },
      "outputs": [],
      "source": [
        "#y_train and y_test contain the labels of each image\n",
        "print(loaded_y_train.shape)\n",
        "print(loaded_y_test.shape)"
      ],
      "id": "e2d0923f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "247cd1a5"
      },
      "source": [
        "# Data Analysis"
      ],
      "id": "247cd1a5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48f225b9"
      },
      "outputs": [],
      "source": [
        "#plotting images\n",
        "plt.figure(figsize=(20,10))\n",
        "for n , i in enumerate(np.random.randint(0,len(loaded_X_train),16)):\n",
        "    plt.subplot(2,8,n+1)\n",
        "    plt.imshow(loaded_X_train[i])\n",
        "    plt.axis('off')\n",
        "    plt.title(getcode(loaded_y_train[i]))"
      ],
      "id": "48f225b9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4562ebf4"
      },
      "outputs": [],
      "source": [
        "#count plot to show the number of skin cancer cases to normal cases in the train data set\n",
        "df_train = pd.DataFrame()\n",
        "df_train[\"labels\"]= loaded_y_train\n",
        "lab = df_train['labels']\n",
        "dist = lab.value_counts()\n",
        "sns.countplot(lab)\n",
        "plt.show()"
      ],
      "id": "4562ebf4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eb27e82"
      },
      "source": [
        "As we can see skin cancer cases are over represented in the train data set. We will deal with such imbalance later"
      ],
      "id": "2eb27e82"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8df765bd"
      },
      "outputs": [],
      "source": [
        "#count plot to show the number of skin cancer cases to normal cases in the test data set\n",
        "\n",
        "df_test = pd.DataFrame()\n",
        "df_test[\"labels\"]= loaded_y_test\n",
        "lab = df_test['labels']\n",
        "dist = lab.value_counts()\n",
        "#play with pallette colors\n",
        "sns.countplot(df_train['labels'])\n",
        "plt.show()"
      ],
      "id": "8df765bd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08f7e8fe"
      },
      "outputs": [],
      "source": [
        "#function to plot the pixel intensity of each image.\n",
        "def plotHistogram(a):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(a)\n",
        "    histo = plt.subplot(1,2,2)\n",
        "    histo.set_ylabel('Count')\n",
        "    histo.set_xlabel('Pixel Intensity')\n",
        "    n_bins = 30\n",
        "    plt.hist(a[:,:,0].flatten(), bins= n_bins, lw = 0, color='r', alpha=0.5)\n",
        "    plt.hist(a[:,:,1].flatten(), bins= n_bins, lw = 0, color='g', alpha=0.5)\n",
        "    plt.hist(a[:,:,2].flatten(), bins= n_bins, lw = 0, color='b', alpha=0.5)"
      ],
      "id": "08f7e8fe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c268ee6"
      },
      "outputs": [],
      "source": [
        "plotHistogram(loaded_X_train[np.random.randint(len(loaded_X_train))])"
      ],
      "id": "8c268ee6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88da30a8"
      },
      "source": [
        "Flatten and shuffle train and test sets"
      ],
      "id": "88da30a8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6194ae97"
      },
      "outputs": [],
      "source": [
        "#flatten the images into a 2d array, for model training and testing\n",
        "X_train = loaded_X_train.reshape([-1, np.product((64,64,3))])\n",
        "X_test = loaded_X_test.reshape([-1, np.product((64,64,3))])"
      ],
      "id": "6194ae97"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "013d3da4"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "id": "013d3da4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2af13a79"
      },
      "outputs": [],
      "source": [
        "y_train = loaded_y_train\n",
        "y_test = loaded_y_test"
      ],
      "id": "2af13a79"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1905bcb2"
      },
      "outputs": [],
      "source": [
        "#shuffle train and test data sets in a consistent way\n",
        "X_train, y_train = shf(X_train, y_train, random_state=15)\n",
        "X_test, y_test = shf(X_test, y_test, random_state=15)"
      ],
      "id": "1905bcb2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b76ad7d0"
      },
      "source": [
        "# Data Preprocessing"
      ],
      "id": "b76ad7d0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "608020a8"
      },
      "outputs": [],
      "source": [
        "#Scaling\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)"
      ],
      "id": "608020a8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecdb832f"
      },
      "source": [
        "we will use Principle Component Analysis (PCA) to reduce the amount of features, to n number of components that represent 0.95% variance of data  "
      ],
      "id": "ecdb832f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a86e64c"
      },
      "outputs": [],
      "source": [
        "#PCA\n",
        "pca = PCA(.95)\n",
        "pca.fit(X_train)\n",
        "X_train = pca.transform(X_train)\n",
        "X_test = pca.transform(X_test)"
      ],
      "id": "7a86e64c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f9a2675"
      },
      "outputs": [],
      "source": [
        "#printing the variance of each component from PCA\n",
        "print('Number of components after PCA: ' + str(pca.n_components_))"
      ],
      "id": "8f9a2675"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab9100cf"
      },
      "source": [
        "# Testing classification algorithms after scaling and PCA"
      ],
      "id": "ab9100cf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db724a6d"
      },
      "outputs": [],
      "source": [
        "#making an instance for each algorithm\n",
        "knn_PCA = KNeighborsClassifier(n_neighbors=3)\n",
        "log_reg_PCA  = LogisticRegression()\n",
        "dtc_PCA  = DecisionTreeClassifier()\n",
        "rfc_PCA = RandomForestClassifier()\n",
        "svm_PCA = SVC()"
      ],
      "id": "db724a6d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4577a050"
      },
      "outputs": [],
      "source": [
        "# fitting each model using X_train and y_train\n",
        "knn_PCA.fit(X_train, y_train)\n",
        "log_reg_PCA.fit(X_train, y_train)\n",
        "dtc_PCA.fit(X_train, y_train)\n",
        "rfc_PCA.fit(X_train, y_train)\n",
        "svm_PCA.fit(X_train, y_train)"
      ],
      "id": "4577a050"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fddb1d53"
      },
      "outputs": [],
      "source": [
        "#scoring each model\n",
        "print('KNN accuracy score is: ' + str(knn_PCA.score(X_test, y_test)))\n",
        "print('Logistic Regression accuracy score is: ' + str(log_reg_PCA.score(X_test, y_test)))\n",
        "print('Decision Tree Classifier accuracy score is: ' + str(dtc_PCA.score(X_test, y_test)))\n",
        "print('Random forests Classifier accuracy score is: ' + str(rfc_PCA.score(X_test, y_test)))\n",
        "print('Support Vector Machine Classifier accuracy score is: ' + str(svm_PCA.score(X_test, y_test)))"
      ],
      "id": "fddb1d53"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a1817b1"
      },
      "source": [
        "The highest accuracy score obtaiend from the support vector machine. As accuracy score is not enough to judge a model we will use confusion matrix"
      ],
      "id": "1a1817b1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d860dd20"
      },
      "outputs": [],
      "source": [
        "#making predictions for each model\n",
        "knn_PCA_predcited = knn_PCA.predict(X_test)\n",
        "log_reg_PCA_predcited = log_reg_PCA.predict(X_test)\n",
        "dtc_PCA_predcited = dtc_PCA.predict(X_test)\n",
        "rfc_PCA_predcited = rfc_PCA.predict(X_test)\n",
        "svm_PCA_predcited = svm_PCA.predict(X_test)"
      ],
      "id": "d860dd20"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec36e94e"
      },
      "outputs": [],
      "source": [
        "def plot_cm(predictions, y_test, title, class_labels):\n",
        "    cm = confusion_matrix(y_test, predictions)\n",
        "    cm = pd.DataFrame(cm, index=class_labels, columns=class_labels)\n",
        "\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    plt.title(title)\n",
        "\n",
        "    sns.heatmap(cm, linecolor='black', linewidth=1, annot=True, fmt='', xticklabels=class_labels, yticklabels=class_labels[::-1])\n",
        "\n",
        "    # Move x-axis ticks to the top\n",
        "    plt.tick_params(axis='x', which='both', bottom=False, top=True)\n",
        "\n",
        "    plt.show()"
      ],
      "id": "ec36e94e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fff4568"
      },
      "outputs": [],
      "source": [
        "#plot confusion matrix for each model after scaling and PCA\n",
        "class_labels = ['basal cell carcinoma','melanoma','pigmented benign keratosis']\n",
        "plot_cm(knn_PCA_predcited, y_test, 'KNN Confusion Matrix After Scaling and PCA',class_labels)\n",
        "\n",
        "plot_cm(log_reg_PCA_predcited, y_test, 'Logistic Regression Confusion Matrix After Scaling and PCA', class_labels)\n",
        "\n",
        "plot_cm(dtc_PCA_predcited, y_test, 'Decision Tree Confusion Matrix After Scaling and PCA', class_labels)\n",
        "\n",
        "plot_cm(rfc_PCA_predcited, y_test, 'Random Forests Confusion Matrix After Scaling and PCA', class_labels)\n",
        "\n",
        "plot_cm(svm_PCA_predcited, y_test, 'Support Vector Machine Confusion Matrix After Scaling and PCA', class_labels)"
      ],
      "id": "0fff4568"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcIPSvulQa1r"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming 'rfc_PCA' is your trained Random Forest Classifier model\n",
        "with open('skin_cancer_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(rfc_PCA, model_file)\n",
        "\n",
        "# Assuming 'sc' is your StandardScaler object\n",
        "with open('standard_scaler.pkl', 'wb') as scaler_file:\n",
        "    pickle.dump(sc, scaler_file)\n",
        "\n",
        "# Assuming 'pca' is your PCA object\n",
        "with open('pca_transformer.pkl', 'wb') as pca_file:\n",
        "    pickle.dump(pca, pca_file)\n"
      ],
      "id": "BcIPSvulQa1r"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 98.114903,
      "end_time": "2023-04-11T12:58:02.748495",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-04-11T12:56:24.633592",
      "version": "2.3.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}